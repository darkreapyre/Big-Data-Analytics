{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification Models  \n",
    "## Introduction  \n",
    "The following Python code demonstrates some basic __Naive Bayes__ classification using Spark. We will create basic Weather data for predicting if someone will 'Play' tennis. The data is hard coded as a list of lists and put into a dataframe. The dataframe is then mapped into an RDD of labeled point vectors. __Notice__ that since `numpy` cannot handle categorical variables, these are recoded as binary indicator variables. For Example, __outlook__ = `sunny`, `overcast` or `rainy`, is replaced by three variables; `sunny` (1 or 0), `overcast` (1 or 0), `rainy` (1 or 0).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the environment\n",
    "import numpy as np\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "# Create the `rawdata`, loosely based on the UHCI weather data set\n",
    "rawdata = [\n",
    "['sunny',85,85,'FALSE',0],\n",
    "['sunny',80,90,'TRUE',0],\n",
    "['overcast',83,86,'FALSE',1],\n",
    "['rainy',70,96,'FALSE',1],\n",
    "['rainy',68,80,'FALSE',1],\n",
    "['rainy',65,70,'TRUE',0],\n",
    "['overcast',64,65,'TRUE',1],\n",
    "['sunny',72,95,'FALSE',0],\n",
    "['sunny',69,70,'FALSE',1],\n",
    "['rainy',75,80,'FALSE',1],\n",
    "['sunny',75,70,'TRUE',1],\n",
    "['overcast',72,90,'TRUE',1],\n",
    "['overcast',81,75,'FALSE',1],\n",
    "['rainy',71,91,'TRUE',0]\n",
    "]\n",
    "\n",
    "# Create a Data Frame from the `rawdata`\n",
    "from pyspark.sql import SQLContext,Row\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "data_df = sqlContext.createDataFrame(rawdata,\n",
    "   ['outlook','temp','humid','windy','play'])\n",
    "\n",
    "# Transform categorical variables into indicator variables\n",
    "out2index = {'sunny':[1,0,0],'overcast':[0,1,0],'rainy':[0,0,1]}\n",
    "\n",
    "# Make an RDD of labeled vectors\n",
    "def newrow(dfrow):\n",
    "    outrow = list(out2index.get((dfrow[0])))  #get dictionary entry for outlook\n",
    "    outrow.append(dfrow[1])   #temp\n",
    "    outrow.append(dfrow[2])   #humidity\n",
    "    if dfrow[3]=='TRUE':      #windy\n",
    "        outrow.append(1)\n",
    "    else:\n",
    "        outrow.append(0)\n",
    "    return (LabeledPoint(dfrow[4],outrow))\n",
    "\n",
    "datax_rdd=data_df.map(newrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verify the __RDD__ data and some basic summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [1.0,0.0,0.0,85.0,85.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,80.0,90.0,1.0]),\n",
       " LabeledPoint(1.0, [0.0,1.0,0.0,83.0,86.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,0.0,1.0,70.0,96.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,0.0,1.0,68.0,80.0,0.0])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datax_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datax_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Naive Bayes Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model object:\n",
      "<pyspark.mllib.classification.NaiveBayesModel object at 0x7f3c593b1250>\n",
      "Model Prediction:\n",
      "[1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Import the the Naive Bayes classifer and train the model\n",
    "import scipy\n",
    "from pyspark.mllib.classification import NaiveBayes\n",
    "\n",
    "my_nbmodel = NaiveBayes.train(datax_rdd)\n",
    "\n",
    "# Verify the rained Model and execute a Prediction\n",
    "datax_col = datax_rdd.collect()\n",
    "trainset_pred =[]\n",
    "for x in datax_col:\n",
    "    trainset_pred.append(my_nbmodel.predict(x.features))\n",
    "\n",
    "print \"Model object:\"\n",
    "print my_nbmodel\n",
    "\n",
    "print \"Model Prediction:\"\n",
    "print trainset_pred"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# View the Class Conditional Probabilities, i.e. p(attr|class = 0 or 1)\n",
    "print \"The log of the Class Conditional Probilities:\"\n",
    "scipy.exp(my_nbmodel.theta)\n",
    "print \"The log of Class Priors:\"\n",
    "scipy.exp(my_nbmodel.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Confusion Matrix:\n",
      "[[ 3.  2.]\n",
      " [ 0.  9.]]\n",
      "Percent Correct:\n",
      "0.857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:5: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# Generate a Confusion Matrix. Note that the  row is the true class label 0 or 1, columns are predicted label.\n",
    "nb_cf_mat=np.zeros([2,2])  #num of classes\n",
    "for pnt in datax_col:\n",
    "    predctn = my_nbmodel.predict(np.array(pnt.features))\n",
    "    nb_cf_mat[pnt.label][predctn]+=1\n",
    "\n",
    "corrcnt=0\n",
    "for i in range(2):\n",
    "    corrcnt+=nb_cf_mat[i][i]\n",
    "nb_per_corr=corrcnt/nb_cf_mat.sum()\n",
    "\n",
    "print \"Naive Bayes Confusion Matrix:\"\n",
    "print nb_cf_mat\n",
    "print \"Percent Correct:\"\n",
    "print nb_per_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Performance by introducing \"Dummy\" Variables  \n",
    "In this scenario, we re-run the model against the same data set, but introduce \"useless\" variables that is constant, after the 'play' column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "#outlook,temperature,humidity,windy,play, copied from Weka's data example\n",
    "rawdata=[\n",
    "['sunny',85,85,'FALSE',0,1],\n",
    "['sunny',80,90,'TRUE',0,1],\n",
    "['overcast',83,86,'FALSE',1,1],\n",
    "['rainy',70,96,'FALSE',1,1],\n",
    "['rainy',68,80,'FALSE',1,1],\n",
    "['rainy',65,70,'TRUE',0,1],\n",
    "['overcast',64,65,'TRUE',1,1],\n",
    "['sunny',72,95,'FALSE',0,1],\n",
    "['sunny',69,70,'FALSE',1,1],\n",
    "['rainy',75,80,'FALSE',1,1],\n",
    "['sunny',75,70,'TRUE',1,1],\n",
    "['overcast',72,90,'TRUE',1,1],\n",
    "['overcast',81,75,'FALSE',1,1],\n",
    "['rainy',71,91,'TRUE',0,1]\n",
    "]\n",
    "\n",
    "from pyspark.sql import SQLContext,Row\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "data_df=sqlContext.createDataFrame(rawdata,\n",
    "                                   ['outlook','temp','humid','windy','play','mydummy']) #<--add field\n",
    "\n",
    "#transform categoricals into indicator variables\n",
    "out2index={'sunny':[1,0,0],'overcast':[0,1,0],'rainy':[0,0,1]}\n",
    "\n",
    "#make RDD of labeled vectors\n",
    "def newrow(dfrow):    \n",
    "    outrow = list(out2index.get((dfrow[0])))  #get dictionary entry\n",
    "    outrow.append(dfrow[1])   #temp    \n",
    "    outrow.append(dfrow[2])   #humidity    \n",
    "    if dfrow[3]=='TRUE':      #windy        \n",
    "        outrow.append(1)    \n",
    "    else:        \n",
    "        outrow.append(0)    \n",
    "    outrow.append(dfrow[5])  # <---- add this     \n",
    "    return (LabeledPoint(dfrow[4],outrow))\n",
    "\n",
    "datax_rdd=data_df.map(newrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [1.0,0.0,0.0,85.0,85.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,0.0,80.0,90.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [0.0,1.0,0.0,83.0,86.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [0.0,0.0,1.0,70.0,96.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [0.0,0.0,1.0,68.0,80.0,0.0,1.0])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datax_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Confusion Matrix:\n",
      "[[ 3.  2.]\n",
      " [ 0.  9.]]\n",
      "Percent Correct:\n",
      "0.857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:22: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes\n",
    "\n",
    "#execute model, it can go in a single pass\n",
    "my_nbmodel = NaiveBayes.train(datax_rdd)\n",
    "\n",
    "#Some info on model \n",
    "#print my_nbmodel\n",
    "#some checks,get some of training data and test it:\n",
    "datax_col=datax_rdd.collect()   #if datax_rdd was big, use sample or take\n",
    "\n",
    "trainset_pred =[]\n",
    "for x in datax_col:\n",
    "    trainset_pred.append(my_nbmodel.predict(x.features))\n",
    "\n",
    "#print trainset_pred\n",
    "\n",
    "#get a confusion matrix\n",
    "#the row is the true class label 0 or 1, columns are predicted label\n",
    "nb_cf_mat=np.zeros([2,2])  #num of classes\n",
    "for pnt in datax_col:\n",
    "    predctn = my_nbmodel.predict(np.array(pnt.features))\n",
    "    nb_cf_mat[pnt.label][predctn]+=1\n",
    "\n",
    "corrcnt=0\n",
    "for i in range(2):\n",
    "    corrcnt+=nb_cf_mat[i][i]\n",
    "nb_per_corr=corrcnt/nb_cf_mat.sum()\n",
    "\n",
    "print \"Naive Bayes Confusion Matrix:\"\n",
    "print nb_cf_mat\n",
    "print \"Percent Correct:\"\n",
    "print nb_per_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Performance on New Unseen Data    \n",
    "In this scenario, we re-run the model against the new data to measure it's performance.\n",
    "The `newpoint` corresponds to the following:\n",
    "\n",
    "- Outlook binary indicator variables = sunny,overcast,rainy\n",
    "- Temperature = 68\n",
    "- Humidy = 79\n",
    "- Windy = 0\n",
    "- Useless-constant (dummy variable) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on new data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new data point\n",
    "newpoint  = np.array([1,0,0,68,79,0,1])\n",
    "\n",
    "# Execute the new test point through the Naive Bayes Model\n",
    "print \"Prediction on new data:\"\n",
    "my_nbmodel.predict(newpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
